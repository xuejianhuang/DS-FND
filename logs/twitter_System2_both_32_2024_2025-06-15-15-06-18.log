2025-06-15 15:06:18,921 - ============================== args ==============================
2025-06-15 15:06:18,921 - dataset: twitter
2025-06-15 15:06:18,921 - model: System2
2025-06-15 15:06:18,921 - batch: 32
2025-06-15 15:06:18,921 - mode: both
2025-06-15 15:06:18,921 - seed: 2024
2025-06-15 15:06:18,921 - ============================== End args ==============================
2025-06-15 15:06:18,921 - ============================== config ==============================
2025-06-15 15:06:18,921 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2025-06-15 15:06:18,921 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2025-06-15 15:06:18,921 - CLIPModel: <class 'transformers.models.clip.modeling_clip.CLIPModel'>
2025-06-15 15:06:18,921 - CLIPProcessor: <class 'transformers.models.clip.processing_clip.CLIPProcessor'>
2025-06-15 15:06:18,921 - att_dropout: 0
2025-06-15 15:06:18,921 - att_num_heads: 8
2025-06-15 15:06:18,921 - batch_size: 32
2025-06-15 15:06:18,921 - bert_dir: ./bert-base-multilingual-uncased/
2025-06-15 15:06:18,921 - classifier_hidden_dim: 128
2025-06-15 15:06:18,921 - clip_dir: ./clip-vit-base-patch32/
2025-06-15 15:06:18,921 - decayRate: 0.96
2025-06-15 15:06:18,922 - device: cuda
2025-06-15 15:06:18,922 - edge_feats: 768
2025-06-15 15:06:18,922 - epoch: 10
2025-06-15 15:06:18,922 - f_dropout: 0
2025-06-15 15:06:18,922 - hidden_dim: 768
2025-06-15 15:06:18,922 - img_dim: 768
2025-06-15 15:06:18,922 - knowledge_enhanced: True
2025-06-15 15:06:18,922 - lr: 5e-05
2025-06-15 15:06:18,922 - max_captions_num: 5
2025-06-15 15:06:18,922 - max_images_num: 5
2025-06-15 15:06:18,922 - model_saved_path: ./checkpoints/
2025-06-15 15:06:18,922 - n_layers: 2
2025-06-15 15:06:18,922 - node_feats: 768
2025-06-15 15:06:18,922 - num_classes: 3
2025-06-15 15:06:18,922 - num_heads: 2
2025-06-15 15:06:18,922 - out_feats: 768
2025-06-15 15:06:18,922 - patience: 3
2025-06-15 15:06:18,922 - pheme_dataset_dir: ../data/PHEME/
2025-06-15 15:06:18,922 - scheduler_bert_freeze: True
2025-06-15 15:06:18,922 - scheduler_swintransformer_freeze: True
2025-06-15 15:06:18,922 - swin_transformer: ./swin-transformer
2025-06-15 15:06:18,922 - sys1_bert_freeze: True
2025-06-15 15:06:18,922 - sys1_clip_freeze: True
2025-06-15 15:06:18,922 - sys1_swintransformer_freeze: True
2025-06-15 15:06:18,922 - sys2_bert_freeze: False
2025-06-15 15:06:18,922 - sys2_clip_freeze: False
2025-06-15 15:06:18,922 - sys2_swintransformer_freeze: False
2025-06-15 15:06:18,922 - test_ratio: 0.1
2025-06-15 15:06:18,922 - text_dim: 768
2025-06-15 15:06:18,922 - text_max_length: 40
2025-06-15 15:06:18,922 - torch: <module 'torch' from '/home/huang001/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>
2025-06-15 15:06:18,922 - train_ratio: 0.8
2025-06-15 15:06:18,922 - twitter_dataset_dir: ../data/Twitter/
2025-06-15 15:06:18,922 - val_ratio: 0.1
2025-06-15 15:06:18,922 - weibo2_dataset_dir: ../data/Weibo+/
2025-06-15 15:06:18,922 - weibo_dataset_dir: ../data/Weibo/
2025-06-15 15:06:18,923 - ============================== End config ==============================
2025-06-15 15:06:26,234 - total number of parameters:390606584
2025-06-15 15:06:26,239 - -----------Epoch:0-----------
2025-06-15 15:06:37,829 - epoch: 0, step: 0, loss: 1.1028, acc: 0.2315
2025-06-15 15:08:14,684 - epoch: 0, step: 10, loss: 0.7475, acc: 0.6667
2025-06-15 15:09:48,642 - epoch: 0, step: 20, loss: 0.4622, acc: 0.6667
2025-06-15 15:11:21,385 - epoch: 0, step: 30, loss: 0.2566, acc: 0.8945
2025-06-15 15:12:50,456 - epoch: 0, step: 40, loss: 0.4316, acc: 0.7444
2025-06-15 15:14:21,649 - epoch: 0, step: 50, loss: 0.3625, acc: 0.8179
2025-06-15 15:15:53,739 - epoch: 0, step: 60, loss: 0.2127, acc: 0.9280
2025-06-15 15:17:21,235 - epoch: 0, step: 70, loss: 0.3861, acc: 0.8215
2025-06-15 15:18:52,742 - epoch: 0, step: 80, loss: 0.1624, acc: 0.9327
2025-06-15 15:20:22,607 - epoch: 0, step: 90, loss: 0.6857, acc: 0.6741
2025-06-15 15:21:52,326 - epoch: 0, step: 100, loss: 0.5515, acc: 0.7056
2025-06-15 15:23:31,512 - epoch: 0, step: 110, loss: 0.1707, acc: 0.9286
2025-06-15 15:24:59,082 - epoch: 0, step: 120, loss: 0.1407, acc: 0.9697
2025-06-15 15:26:27,797 - epoch: 0, step: 130, loss: 0.0669, acc: 1.0000
2025-06-15 15:28:06,940 - epoch: 0, step: 140, loss: 0.2785, acc: 0.8750
2025-06-15 15:29:35,983 - epoch: 0, step: 150, loss: 0.4093, acc: 0.8125
2025-06-15 15:29:49,465 - train_loss:0.38082 train_acc:0.810
2025-06-15 15:32:20,738 - val_loss:0.20536 val_acc:0.918 

2025-06-15 15:32:23,745 - save model,acc:0.918
2025-06-15 15:32:23,746 - -----------Epoch:1-----------
2025-06-15 15:32:33,889 - epoch: 1, step: 0, loss: 0.0972, acc: 1.0000
2025-06-15 15:34:02,887 - epoch: 1, step: 10, loss: 0.1059, acc: 0.9556
2025-06-15 15:35:33,799 - epoch: 1, step: 20, loss: 0.1265, acc: 0.8704
2025-06-15 15:37:07,864 - epoch: 1, step: 30, loss: 0.0641, acc: 1.0000
2025-06-15 15:38:35,030 - epoch: 1, step: 40, loss: 0.0767, acc: 1.0000
2025-06-15 15:40:03,037 - epoch: 1, step: 50, loss: 0.0558, acc: 1.0000
2025-06-15 15:41:31,370 - epoch: 1, step: 60, loss: 0.1965, acc: 0.9167
2025-06-15 15:43:00,347 - epoch: 1, step: 70, loss: 0.2896, acc: 0.9444
2025-06-15 15:44:29,227 - epoch: 1, step: 80, loss: 0.0543, acc: 1.0000
2025-06-15 15:46:04,313 - epoch: 1, step: 90, loss: 0.0739, acc: 0.9722
2025-06-15 15:47:33,645 - epoch: 1, step: 100, loss: 0.0464, acc: 1.0000
2025-06-15 15:49:05,406 - epoch: 1, step: 110, loss: 0.0548, acc: 1.0000
2025-06-15 15:50:40,722 - epoch: 1, step: 120, loss: 0.2209, acc: 0.9267
2025-06-15 15:52:16,742 - epoch: 1, step: 130, loss: 0.2623, acc: 0.9206
2025-06-15 15:53:53,522 - epoch: 1, step: 140, loss: 0.0745, acc: 1.0000
2025-06-15 15:55:24,520 - epoch: 1, step: 150, loss: 0.0416, acc: 1.0000
2025-06-15 15:55:39,850 - train_loss:0.11506 train_acc:0.956
2025-06-15 15:58:13,239 - val_loss:0.14130 val_acc:0.952 

2025-06-15 15:58:16,228 - save model,acc:0.952
2025-06-15 15:58:16,228 - -----------Epoch:2-----------
2025-06-15 15:58:26,107 - epoch: 2, step: 0, loss: 0.0187, acc: 1.0000
2025-06-15 16:00:01,935 - epoch: 2, step: 10, loss: 0.0126, acc: 1.0000
2025-06-15 16:01:29,845 - epoch: 2, step: 20, loss: 0.0861, acc: 0.9815
2025-06-15 16:03:01,799 - epoch: 2, step: 30, loss: 0.0191, acc: 1.0000
2025-06-15 16:04:30,213 - epoch: 2, step: 40, loss: 0.0242, acc: 1.0000
2025-06-15 16:06:03,351 - epoch: 2, step: 50, loss: 0.1079, acc: 0.9267
2025-06-15 16:07:28,635 - epoch: 2, step: 60, loss: 0.0858, acc: 0.9524
2025-06-15 16:09:00,698 - epoch: 2, step: 70, loss: 0.1001, acc: 0.9792
2025-06-15 16:10:33,268 - epoch: 2, step: 80, loss: 0.1146, acc: 0.8889
2025-06-15 16:12:01,611 - epoch: 2, step: 90, loss: 0.0098, acc: 1.0000
2025-06-15 16:13:29,485 - epoch: 2, step: 100, loss: 0.1236, acc: 0.9630
2025-06-15 16:14:59,312 - epoch: 2, step: 110, loss: 0.0399, acc: 1.0000
2025-06-15 16:16:35,697 - epoch: 2, step: 120, loss: 0.0732, acc: 0.9583
2025-06-15 16:18:08,288 - epoch: 2, step: 130, loss: 0.0177, acc: 1.0000
2025-06-15 16:19:38,636 - epoch: 2, step: 140, loss: 0.1500, acc: 0.9444
2025-06-15 16:21:07,458 - epoch: 2, step: 150, loss: 0.0709, acc: 0.9841
2025-06-15 16:21:22,547 - train_loss:0.06397 train_acc:0.973
2025-06-15 16:23:54,706 - val_loss:0.31134 val_acc:0.899 

2025-06-15 16:23:54,706 - -----------Epoch:3-----------
2025-06-15 16:24:03,807 - epoch: 3, step: 0, loss: 0.0895, acc: 0.9153
2025-06-15 16:25:37,388 - epoch: 3, step: 10, loss: 0.0285, acc: 1.0000
2025-06-15 16:27:10,324 - epoch: 3, step: 20, loss: 0.0296, acc: 1.0000
2025-06-15 16:28:47,575 - epoch: 3, step: 30, loss: 0.0185, acc: 1.0000
2025-06-15 16:30:19,882 - epoch: 3, step: 40, loss: 0.1460, acc: 0.9345
2025-06-15 16:31:49,212 - epoch: 3, step: 50, loss: 0.0386, acc: 0.9583
2025-06-15 16:33:20,481 - epoch: 3, step: 60, loss: 0.0082, acc: 1.0000
2025-06-15 16:34:48,043 - epoch: 3, step: 70, loss: 0.0039, acc: 1.0000
2025-06-15 16:36:18,319 - epoch: 3, step: 80, loss: 0.0966, acc: 0.9667
2025-06-15 16:37:45,694 - epoch: 3, step: 90, loss: 0.0049, acc: 1.0000
2025-06-15 16:39:18,789 - epoch: 3, step: 100, loss: 0.1027, acc: 0.9630
2025-06-15 16:40:51,171 - epoch: 3, step: 110, loss: 0.0087, acc: 1.0000
2025-06-15 16:42:22,457 - epoch: 3, step: 120, loss: 0.0144, acc: 1.0000
2025-06-15 16:43:51,382 - epoch: 3, step: 130, loss: 0.0324, acc: 0.9697
2025-06-15 16:45:18,638 - epoch: 3, step: 140, loss: 0.0468, acc: 0.9630
2025-06-15 16:46:46,760 - epoch: 3, step: 150, loss: 0.0239, acc: 1.0000
2025-06-15 16:47:00,021 - train_loss:0.04501 train_acc:0.980
2025-06-15 16:49:31,668 - val_loss:0.15837 val_acc:0.940 

2025-06-15 16:49:31,668 - -----------Epoch:4-----------
2025-06-15 16:49:42,885 - epoch: 4, step: 0, loss: 0.0248, acc: 0.9524
2025-06-15 16:51:13,376 - epoch: 4, step: 10, loss: 0.0029, acc: 1.0000
2025-06-15 16:52:36,119 - epoch: 4, step: 20, loss: 0.0098, acc: 1.0000
2025-06-15 16:54:07,949 - epoch: 4, step: 30, loss: 0.0011, acc: 1.0000
2025-06-15 16:55:37,394 - epoch: 4, step: 40, loss: 0.0031, acc: 1.0000
2025-06-15 16:57:09,292 - epoch: 4, step: 50, loss: 0.1002, acc: 0.9444
2025-06-15 16:58:43,779 - epoch: 4, step: 60, loss: 0.0013, acc: 1.0000
2025-06-15 17:00:17,750 - epoch: 4, step: 70, loss: 0.0029, acc: 1.0000
2025-06-15 17:01:49,256 - epoch: 4, step: 80, loss: 0.0028, acc: 1.0000
2025-06-15 17:03:22,903 - epoch: 4, step: 90, loss: 0.0036, acc: 1.0000
2025-06-15 17:04:58,721 - epoch: 4, step: 100, loss: 0.0104, acc: 1.0000
2025-06-15 17:06:24,659 - epoch: 4, step: 110, loss: 0.0004, acc: 1.0000
2025-06-15 17:08:00,662 - epoch: 4, step: 120, loss: 0.0016, acc: 1.0000
2025-06-15 17:09:25,393 - epoch: 4, step: 130, loss: 0.0554, acc: 0.9744
2025-06-15 17:10:57,706 - epoch: 4, step: 140, loss: 0.0049, acc: 1.0000
2025-06-15 17:12:25,683 - epoch: 4, step: 150, loss: 0.0129, acc: 1.0000
2025-06-15 17:12:38,627 - train_loss:0.01594 train_acc:0.994
2025-06-15 17:15:10,571 - val_loss:0.11118 val_acc:0.961 

2025-06-15 17:15:13,504 - save model,acc:0.961
2025-06-15 17:15:13,504 - -----------Epoch:5-----------
2025-06-15 17:15:22,355 - epoch: 5, step: 0, loss: 0.0027, acc: 1.0000
2025-06-15 17:16:51,865 - epoch: 5, step: 10, loss: 0.0146, acc: 1.0000
2025-06-15 17:18:23,237 - epoch: 5, step: 20, loss: 0.0014, acc: 1.0000
2025-06-15 17:19:53,005 - epoch: 5, step: 30, loss: 0.0018, acc: 1.0000
2025-06-15 17:21:24,676 - epoch: 5, step: 40, loss: 0.0114, acc: 1.0000
2025-06-15 17:23:01,170 - epoch: 5, step: 50, loss: 0.0013, acc: 1.0000
2025-06-15 17:24:28,700 - epoch: 5, step: 60, loss: 0.0008, acc: 1.0000
2025-06-15 17:25:53,978 - epoch: 5, step: 70, loss: 0.0040, acc: 1.0000
2025-06-15 17:27:20,516 - epoch: 5, step: 80, loss: 0.0045, acc: 1.0000
2025-06-15 17:28:54,604 - epoch: 5, step: 90, loss: 0.0005, acc: 1.0000
2025-06-15 17:30:26,925 - epoch: 5, step: 100, loss: 0.0008, acc: 1.0000
2025-06-15 17:31:56,913 - epoch: 5, step: 110, loss: 0.0006, acc: 1.0000
2025-06-15 17:33:27,453 - epoch: 5, step: 120, loss: 0.0011, acc: 1.0000
2025-06-15 17:34:57,552 - epoch: 5, step: 130, loss: 0.0008, acc: 1.0000
2025-06-15 17:36:24,709 - epoch: 5, step: 140, loss: 0.0285, acc: 0.9333
2025-06-15 17:38:00,953 - epoch: 5, step: 150, loss: 0.0006, acc: 1.0000
2025-06-15 17:38:15,440 - train_loss:0.00452 train_acc:0.999
2025-06-15 17:40:45,834 - val_loss:0.14150 val_acc:0.952 

2025-06-15 17:40:45,834 - -----------Epoch:6-----------
2025-06-15 17:40:54,386 - epoch: 6, step: 0, loss: 0.0021, acc: 1.0000
2025-06-15 17:42:21,019 - epoch: 6, step: 10, loss: 0.0001, acc: 1.0000
2025-06-15 17:43:49,348 - epoch: 6, step: 20, loss: 0.0003, acc: 1.0000
2025-06-15 17:45:21,355 - epoch: 6, step: 30, loss: 0.0002, acc: 1.0000
2025-06-15 17:46:54,724 - epoch: 6, step: 40, loss: 0.0015, acc: 1.0000
2025-06-15 17:48:21,825 - epoch: 6, step: 50, loss: 0.0014, acc: 1.0000
2025-06-15 17:49:51,493 - epoch: 6, step: 60, loss: 0.0003, acc: 1.0000
2025-06-15 17:51:20,633 - epoch: 6, step: 70, loss: 0.0015, acc: 1.0000
2025-06-15 17:52:49,875 - epoch: 6, step: 80, loss: 0.0011, acc: 1.0000
2025-06-15 17:54:27,759 - epoch: 6, step: 90, loss: 0.0001, acc: 1.0000
2025-06-15 17:55:59,351 - epoch: 6, step: 100, loss: 0.0058, acc: 1.0000
2025-06-15 17:57:26,774 - epoch: 6, step: 110, loss: 0.0022, acc: 1.0000
2025-06-15 17:58:59,030 - epoch: 6, step: 120, loss: 0.0009, acc: 1.0000
2025-06-15 18:00:31,491 - epoch: 6, step: 130, loss: 0.0015, acc: 1.0000
2025-06-15 18:01:56,925 - epoch: 6, step: 140, loss: 0.0004, acc: 1.0000
2025-06-15 18:03:26,612 - epoch: 6, step: 150, loss: 0.0047, acc: 1.0000
2025-06-15 18:03:42,286 - train_loss:0.00330 train_acc:0.999
2025-06-15 18:06:10,511 - val_loss:0.28492 val_acc:0.932 

2025-06-15 18:06:10,511 - -----------Epoch:7-----------
2025-06-15 18:06:19,706 - epoch: 7, step: 0, loss: 0.1618, acc: 0.9444
2025-06-15 18:07:44,096 - epoch: 7, step: 10, loss: 0.0841, acc: 0.9583
2025-06-15 18:09:15,014 - epoch: 7, step: 20, loss: 0.0012, acc: 1.0000
2025-06-15 18:10:43,563 - epoch: 7, step: 30, loss: 0.1163, acc: 0.9744
2025-06-15 18:12:16,825 - epoch: 7, step: 40, loss: 0.0023, acc: 1.0000
2025-06-15 18:13:49,687 - epoch: 7, step: 50, loss: 0.0012, acc: 1.0000
2025-06-15 18:15:24,391 - epoch: 7, step: 60, loss: 0.0004, acc: 1.0000
2025-06-15 18:16:55,223 - epoch: 7, step: 70, loss: 0.0056, acc: 1.0000
2025-06-15 18:18:25,583 - epoch: 7, step: 80, loss: 0.0053, acc: 1.0000
2025-06-15 18:19:56,045 - epoch: 7, step: 90, loss: 0.0028, acc: 1.0000
2025-06-15 18:21:30,520 - epoch: 7, step: 100, loss: 0.0031, acc: 1.0000
2025-06-15 18:22:53,990 - epoch: 7, step: 110, loss: 0.0051, acc: 1.0000
2025-06-15 18:24:22,969 - epoch: 7, step: 120, loss: 0.0015, acc: 1.0000
2025-06-15 18:25:52,996 - epoch: 7, step: 130, loss: 0.0026, acc: 1.0000
2025-06-15 18:27:27,354 - epoch: 7, step: 140, loss: 0.0012, acc: 1.0000
2025-06-15 18:28:56,603 - epoch: 7, step: 150, loss: 0.0035, acc: 1.0000
2025-06-15 18:29:08,693 - train_loss:0.01301 train_acc:0.995
2025-06-15 18:31:37,015 - val_loss:0.14255 val_acc:0.959 

2025-06-15 18:34:05,617 - --------------------- test results-------------------------------
2025-06-15 18:34:05,617 - acc:0.9528712  prec:[0.9951923 0.877193  0.9653979]  rec:[0.96728975 0.9259259  0.9653979 ]  f1:[0.9810427 0.9009009 0.9653979]
2025-06-15 18:34:05,618 - confusion: 
[[207   5   2]
 [  0 100   8]
 [  1   9 279]]
2025-06-15 18:34:05,618 - the running time is: 12459.4 s
