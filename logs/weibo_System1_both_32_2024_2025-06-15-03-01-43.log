2025-06-15 03:01:43,705 - ============================== args ==============================
2025-06-15 03:01:43,705 - dataset: weibo
2025-06-15 03:01:43,705 - model: System1
2025-06-15 03:01:43,705 - batch: 32
2025-06-15 03:01:43,705 - mode: both
2025-06-15 03:01:43,705 - seed: 2024
2025-06-15 03:01:43,705 - ============================== End args ==============================
2025-06-15 03:01:43,705 - ============================== config ==============================
2025-06-15 03:01:43,705 - BertModel: <class 'transformers.models.bert.modeling_bert.BertModel'>
2025-06-15 03:01:43,705 - BertTokenizer: <class 'transformers.models.bert.tokenization_bert.BertTokenizer'>
2025-06-15 03:01:43,705 - CLIPModel: <class 'transformers.models.clip.modeling_clip.CLIPModel'>
2025-06-15 03:01:43,705 - CLIPProcessor: <class 'transformers.models.clip.processing_clip.CLIPProcessor'>
2025-06-15 03:01:43,705 - att_dropout: 0
2025-06-15 03:01:43,705 - att_num_heads: 8
2025-06-15 03:01:43,705 - batch_size: 32
2025-06-15 03:01:43,705 - bert_dir: ./bert-base-multilingual-uncased/
2025-06-15 03:01:43,706 - classifier_hidden_dim: 128
2025-06-15 03:01:43,706 - clip_dir: ./clip-vit-base-patch32/
2025-06-15 03:01:43,706 - decayRate: 0.96
2025-06-15 03:01:43,706 - device: cuda
2025-06-15 03:01:43,706 - edge_feats: 768
2025-06-15 03:01:43,706 - epoch: 10
2025-06-15 03:01:43,706 - f_dropout: 0
2025-06-15 03:01:43,706 - hidden_dim: 768
2025-06-15 03:01:43,706 - img_dim: 768
2025-06-15 03:01:43,706 - knowledge_enhanced: True
2025-06-15 03:01:43,706 - lr: 5e-05
2025-06-15 03:01:43,706 - max_captions_num: 5
2025-06-15 03:01:43,706 - max_images_num: 5
2025-06-15 03:01:43,706 - model_saved_path: ./checkpoints/
2025-06-15 03:01:43,706 - n_layers: 2
2025-06-15 03:01:43,706 - node_feats: 768
2025-06-15 03:01:43,706 - num_classes: 3
2025-06-15 03:01:43,706 - num_heads: 2
2025-06-15 03:01:43,706 - out_feats: 768
2025-06-15 03:01:43,706 - patience: 3
2025-06-15 03:01:43,706 - pheme_dataset_dir: ../data/PHEME/
2025-06-15 03:01:43,706 - scheduler_bert_freeze: True
2025-06-15 03:01:43,706 - scheduler_swintransformer_freeze: True
2025-06-15 03:01:43,706 - swin_transformer: ./swin-transformer
2025-06-15 03:01:43,706 - sys1_bert_freeze: True
2025-06-15 03:01:43,706 - sys1_clip_freeze: True
2025-06-15 03:01:43,706 - sys1_swintransformer_freeze: True
2025-06-15 03:01:43,706 - sys2_bert_freeze: False
2025-06-15 03:01:43,706 - sys2_clip_freeze: False
2025-06-15 03:01:43,706 - sys2_swintransformer_freeze: False
2025-06-15 03:01:43,706 - test_ratio: 0.1
2025-06-15 03:01:43,706 - text_dim: 768
2025-06-15 03:01:43,706 - text_max_length: 40
2025-06-15 03:01:43,706 - torch: <module 'torch' from '/home/huang001/anaconda3/lib/python3.11/site-packages/torch/__init__.py'>
2025-06-15 03:01:43,706 - train_ratio: 0.8
2025-06-15 03:01:43,706 - twitter_dataset_dir: ../data/Twitter/
2025-06-15 03:01:43,706 - val_ratio: 0.1
2025-06-15 03:01:43,707 - weibo2_dataset_dir: ../data/Weibo+/
2025-06-15 03:01:43,707 - weibo_dataset_dir: ../data/Weibo/
2025-06-15 03:01:43,707 - ============================== End config ==============================
2025-06-15 03:01:44,683 - total number of parameters:2459651
2025-06-15 03:01:44,687 - -----------Epoch:0-----------
2025-06-15 03:01:51,538 - epoch: 0, step: 0, loss: 1.0817, acc: 0.3833
2025-06-15 03:02:37,550 - epoch: 0, step: 10, loss: 1.0847, acc: 0.3750
2025-06-15 03:03:28,185 - epoch: 0, step: 20, loss: 1.0037, acc: 0.4558
2025-06-15 03:04:10,657 - epoch: 0, step: 30, loss: 0.9264, acc: 0.4333
2025-06-15 03:04:52,419 - epoch: 0, step: 40, loss: 0.8745, acc: 0.5085
2025-06-15 03:05:38,890 - epoch: 0, step: 50, loss: 0.7632, acc: 0.6806
2025-06-15 03:06:31,223 - epoch: 0, step: 60, loss: 0.8160, acc: 0.7714
2025-06-15 03:07:18,042 - epoch: 0, step: 70, loss: 0.7385, acc: 0.7262
2025-06-15 03:08:01,934 - epoch: 0, step: 80, loss: 0.7076, acc: 0.5556
2025-06-15 03:08:41,388 - epoch: 0, step: 90, loss: 0.8131, acc: 0.6537
2025-06-15 03:09:20,352 - epoch: 0, step: 100, loss: 0.6747, acc: 0.7051
2025-06-15 03:10:05,563 - epoch: 0, step: 110, loss: 0.7515, acc: 0.5840
2025-06-15 03:10:43,968 - epoch: 0, step: 120, loss: 0.6095, acc: 0.7632
2025-06-15 03:11:23,747 - epoch: 0, step: 130, loss: 0.6167, acc: 0.7491
2025-06-15 03:12:04,243 - epoch: 0, step: 140, loss: 0.4273, acc: 0.8287
2025-06-15 03:12:46,846 - epoch: 0, step: 150, loss: 0.4604, acc: 0.7679
2025-06-15 03:13:25,105 - epoch: 0, step: 160, loss: 0.4706, acc: 0.8690
2025-06-15 03:14:06,266 - epoch: 0, step: 170, loss: 0.6599, acc: 0.6722
2025-06-15 03:14:47,233 - epoch: 0, step: 180, loss: 0.6767, acc: 0.7722
2025-06-15 03:15:34,528 - epoch: 0, step: 190, loss: 0.6761, acc: 0.6019
2025-06-15 03:15:44,317 - train_loss:0.74080 train_acc:0.651
2025-06-15 03:17:24,725 - val_loss:0.55139 val_acc:0.769 

2025-06-15 03:17:27,847 - save model,acc:0.769
2025-06-15 03:17:27,847 - -----------Epoch:1-----------
2025-06-15 03:17:32,725 - epoch: 1, step: 0, loss: 0.4927, acc: 0.7713
2025-06-15 03:18:11,028 - epoch: 1, step: 10, loss: 0.4380, acc: 0.9213
2025-06-15 03:18:49,254 - epoch: 1, step: 20, loss: 0.5691, acc: 0.7500
2025-06-15 03:19:23,940 - epoch: 1, step: 30, loss: 0.4453, acc: 0.8455
2025-06-15 03:20:08,556 - epoch: 1, step: 40, loss: 0.5961, acc: 0.8117
2025-06-15 03:20:50,352 - epoch: 1, step: 50, loss: 0.6180, acc: 0.8472
2025-06-15 03:21:32,181 - epoch: 1, step: 60, loss: 0.4298, acc: 0.9052
2025-06-15 03:22:10,591 - epoch: 1, step: 70, loss: 0.4458, acc: 0.8582
2025-06-15 03:22:52,935 - epoch: 1, step: 80, loss: 0.3951, acc: 0.9667
2025-06-15 03:23:46,160 - epoch: 1, step: 90, loss: 0.3741, acc: 0.8971
2025-06-15 03:24:37,535 - epoch: 1, step: 100, loss: 0.2703, acc: 0.8389
2025-06-15 03:25:24,683 - epoch: 1, step: 110, loss: 0.4628, acc: 0.8278
2025-06-15 03:26:12,025 - epoch: 1, step: 120, loss: 0.5661, acc: 0.7900
2025-06-15 03:26:53,573 - epoch: 1, step: 130, loss: 0.5220, acc: 0.7804
2025-06-15 03:27:37,170 - epoch: 1, step: 140, loss: 0.4535, acc: 0.8419
2025-06-15 03:28:21,071 - epoch: 1, step: 150, loss: 0.3318, acc: 0.8308
2025-06-15 03:28:59,722 - epoch: 1, step: 160, loss: 0.2722, acc: 0.7917
2025-06-15 03:29:42,239 - epoch: 1, step: 170, loss: 0.3652, acc: 0.8688
2025-06-15 03:30:29,254 - epoch: 1, step: 180, loss: 0.5238, acc: 0.7683
2025-06-15 03:31:13,695 - epoch: 1, step: 190, loss: 0.3739, acc: 0.7500
2025-06-15 03:31:19,319 - train_loss:0.44981 train_acc:0.823
2025-06-15 03:32:59,975 - val_loss:0.49302 val_acc:0.761 

2025-06-15 03:32:59,975 - -----------Epoch:2-----------
2025-06-15 03:33:05,745 - epoch: 2, step: 0, loss: 0.3379, acc: 0.8401
2025-06-15 03:33:49,259 - epoch: 2, step: 10, loss: 0.3940, acc: 0.9094
2025-06-15 03:34:37,367 - epoch: 2, step: 20, loss: 0.3257, acc: 0.9471
2025-06-15 03:35:22,756 - epoch: 2, step: 30, loss: 0.6327, acc: 0.7575
2025-06-15 03:36:09,928 - epoch: 2, step: 40, loss: 0.5564, acc: 0.8381
2025-06-15 03:36:56,640 - epoch: 2, step: 50, loss: 0.3953, acc: 0.8037
2025-06-15 03:37:38,804 - epoch: 2, step: 60, loss: 0.3126, acc: 0.8204
2025-06-15 03:38:16,745 - epoch: 2, step: 70, loss: 0.4315, acc: 0.8403
2025-06-15 03:38:58,075 - epoch: 2, step: 80, loss: 0.2247, acc: 0.8810
2025-06-15 03:39:38,389 - epoch: 2, step: 90, loss: 0.4959, acc: 0.7845
2025-06-15 03:40:28,659 - epoch: 2, step: 100, loss: 0.2423, acc: 0.9188
2025-06-15 03:41:15,462 - epoch: 2, step: 110, loss: 0.2840, acc: 0.8796
2025-06-15 03:41:53,966 - epoch: 2, step: 120, loss: 0.3784, acc: 0.8519
2025-06-15 03:42:36,208 - epoch: 2, step: 130, loss: 0.2475, acc: 0.9190
2025-06-15 03:43:18,179 - epoch: 2, step: 140, loss: 0.3011, acc: 0.8945
2025-06-15 03:43:57,450 - epoch: 2, step: 150, loss: 0.3473, acc: 0.7905
2025-06-15 03:44:39,392 - epoch: 2, step: 160, loss: 0.3190, acc: 0.9191
2025-06-15 03:45:17,093 - epoch: 2, step: 170, loss: 0.4221, acc: 0.8814
2025-06-15 03:45:56,920 - epoch: 2, step: 180, loss: 0.4766, acc: 0.7906
2025-06-15 03:46:43,030 - epoch: 2, step: 190, loss: 0.3123, acc: 0.8333
2025-06-15 03:46:47,249 - train_loss:0.36772 train_acc:0.856
2025-06-15 03:48:28,030 - val_loss:0.39827 val_acc:0.835 

2025-06-15 03:48:30,823 - save model,acc:0.835
2025-06-15 03:48:30,823 - -----------Epoch:3-----------
2025-06-15 03:48:33,687 - epoch: 3, step: 0, loss: 0.3037, acc: 0.9387
2025-06-15 03:49:19,612 - epoch: 3, step: 10, loss: 0.3473, acc: 0.8611
2025-06-15 03:50:02,651 - epoch: 3, step: 20, loss: 0.2776, acc: 0.9481
2025-06-15 03:50:44,274 - epoch: 3, step: 30, loss: 0.3278, acc: 0.9221
2025-06-15 03:51:28,999 - epoch: 3, step: 40, loss: 0.3884, acc: 0.8586
2025-06-15 03:52:07,691 - epoch: 3, step: 50, loss: 0.5943, acc: 0.7032
2025-06-15 03:52:49,735 - epoch: 3, step: 60, loss: 0.5182, acc: 0.7261
2025-06-15 03:53:37,134 - epoch: 3, step: 70, loss: 0.2785, acc: 0.9153
2025-06-15 03:54:22,243 - epoch: 3, step: 80, loss: 0.1769, acc: 0.9524
2025-06-15 03:54:59,960 - epoch: 3, step: 90, loss: 0.3183, acc: 0.8578
2025-06-15 03:55:41,981 - epoch: 3, step: 100, loss: 0.3125, acc: 0.9410
2025-06-15 03:56:29,466 - epoch: 3, step: 110, loss: 0.3618, acc: 0.6944
2025-06-15 03:57:15,961 - epoch: 3, step: 120, loss: 0.3677, acc: 0.9000
2025-06-15 03:58:01,159 - epoch: 3, step: 130, loss: 0.2528, acc: 0.9213
2025-06-15 03:58:44,936 - epoch: 3, step: 140, loss: 0.2630, acc: 0.8843
2025-06-15 03:59:24,773 - epoch: 3, step: 150, loss: 0.3230, acc: 0.7505
2025-06-15 04:00:08,927 - epoch: 3, step: 160, loss: 0.3313, acc: 0.7787
2025-06-15 04:00:51,931 - epoch: 3, step: 170, loss: 0.2599, acc: 0.8678
2025-06-15 04:01:38,641 - epoch: 3, step: 180, loss: 0.3694, acc: 0.8042
2025-06-15 04:02:13,002 - epoch: 3, step: 190, loss: 0.2042, acc: 0.9444
2025-06-15 04:02:20,515 - train_loss:0.32373 train_acc:0.874
2025-06-15 04:04:01,578 - val_loss:0.38779 val_acc:0.853 

2025-06-15 04:04:04,440 - save model,acc:0.853
2025-06-15 04:04:04,440 - -----------Epoch:4-----------
2025-06-15 04:04:07,624 - epoch: 4, step: 0, loss: 0.2159, acc: 0.8429
2025-06-15 04:04:49,568 - epoch: 4, step: 10, loss: 0.3901, acc: 0.8452
2025-06-15 04:05:34,706 - epoch: 4, step: 20, loss: 0.3092, acc: 0.8500
2025-06-15 04:06:26,350 - epoch: 4, step: 30, loss: 0.3194, acc: 0.8575
2025-06-15 04:07:10,287 - epoch: 4, step: 40, loss: 0.3096, acc: 0.8968
2025-06-15 04:07:54,440 - epoch: 4, step: 50, loss: 0.4753, acc: 0.8019
2025-06-15 04:08:37,739 - epoch: 4, step: 60, loss: 0.3338, acc: 0.8403
2025-06-15 04:09:15,640 - epoch: 4, step: 70, loss: 0.3239, acc: 0.8791
2025-06-15 04:09:54,884 - epoch: 4, step: 80, loss: 0.1789, acc: 0.9630
2025-06-15 04:10:44,618 - epoch: 4, step: 90, loss: 0.2757, acc: 0.9222
2025-06-15 04:11:30,252 - epoch: 4, step: 100, loss: 0.2693, acc: 0.8864
2025-06-15 04:12:11,333 - epoch: 4, step: 110, loss: 0.2922, acc: 0.9095
2025-06-15 04:12:49,654 - epoch: 4, step: 120, loss: 0.3541, acc: 0.8077
2025-06-15 04:13:32,610 - epoch: 4, step: 130, loss: 0.2438, acc: 0.9722
2025-06-15 04:14:21,463 - epoch: 4, step: 140, loss: 0.4457, acc: 0.7823
2025-06-15 04:15:00,924 - epoch: 4, step: 150, loss: 0.2282, acc: 0.8632
2025-06-15 04:15:38,292 - epoch: 4, step: 160, loss: 0.3192, acc: 0.8333
2025-06-15 04:16:19,015 - epoch: 4, step: 170, loss: 0.3564, acc: 0.8475
2025-06-15 04:17:06,316 - epoch: 4, step: 180, loss: 0.1515, acc: 0.9792
2025-06-15 04:17:51,087 - epoch: 4, step: 190, loss: 0.4275, acc: 0.8352
2025-06-15 04:17:57,552 - train_loss:0.29632 train_acc:0.880
2025-06-15 04:19:37,570 - val_loss:0.34324 val_acc:0.881 

2025-06-15 04:19:40,360 - save model,acc:0.881
2025-06-15 04:19:40,360 - -----------Epoch:5-----------
2025-06-15 04:19:44,886 - epoch: 5, step: 0, loss: 0.2679, acc: 0.8376
2025-06-15 04:20:22,897 - epoch: 5, step: 10, loss: 0.2158, acc: 0.9583
2025-06-15 04:21:01,330 - epoch: 5, step: 20, loss: 0.1635, acc: 1.0000
2025-06-15 04:21:41,609 - epoch: 5, step: 30, loss: 0.2483, acc: 0.9466
2025-06-15 04:22:27,430 - epoch: 5, step: 40, loss: 0.4704, acc: 0.7697
2025-06-15 04:23:13,922 - epoch: 5, step: 50, loss: 0.2812, acc: 0.9333
2025-06-15 04:23:55,099 - epoch: 5, step: 60, loss: 0.4278, acc: 0.8667
2025-06-15 04:24:33,144 - epoch: 5, step: 70, loss: 0.2055, acc: 0.9630
2025-06-15 04:25:13,773 - epoch: 5, step: 80, loss: 0.3537, acc: 0.8746
2025-06-15 04:26:07,993 - epoch: 5, step: 90, loss: 0.2129, acc: 0.8997
2025-06-15 04:26:46,895 - epoch: 5, step: 100, loss: 0.2591, acc: 0.9125
2025-06-15 04:27:36,924 - epoch: 5, step: 110, loss: 0.1667, acc: 0.9815
2025-06-15 04:28:20,656 - epoch: 5, step: 120, loss: 0.3033, acc: 0.8783
2025-06-15 04:29:04,258 - epoch: 5, step: 130, loss: 0.1846, acc: 0.9630
2025-06-15 04:29:46,343 - epoch: 5, step: 140, loss: 0.2294, acc: 0.9061
2025-06-15 04:30:31,777 - epoch: 5, step: 150, loss: 0.2367, acc: 0.9535
2025-06-15 04:31:15,036 - epoch: 5, step: 160, loss: 0.1875, acc: 0.8722
2025-06-15 04:32:01,028 - epoch: 5, step: 170, loss: 0.2047, acc: 0.9148
2025-06-15 04:32:43,735 - epoch: 5, step: 180, loss: 0.3126, acc: 0.8283
2025-06-15 04:33:28,902 - epoch: 5, step: 190, loss: 0.2288, acc: 0.8767
2025-06-15 04:33:36,262 - train_loss:0.27013 train_acc:0.898
2025-06-15 04:35:16,380 - val_loss:0.35273 val_acc:0.873 

2025-06-15 04:35:16,381 - -----------Epoch:6-----------
2025-06-15 04:35:22,354 - epoch: 6, step: 0, loss: 0.2205, acc: 0.8889
2025-06-15 04:36:12,078 - epoch: 6, step: 10, loss: 0.1408, acc: 0.9825
2025-06-15 04:36:56,778 - epoch: 6, step: 20, loss: 0.2743, acc: 0.7685
2025-06-15 04:37:35,835 - epoch: 6, step: 30, loss: 0.3652, acc: 0.8990
2025-06-15 04:38:19,564 - epoch: 6, step: 40, loss: 0.3346, acc: 0.8215
2025-06-15 04:39:03,448 - epoch: 6, step: 50, loss: 0.3174, acc: 0.8394
2025-06-15 04:39:42,286 - epoch: 6, step: 60, loss: 0.4410, acc: 0.8444
2025-06-15 04:40:24,981 - epoch: 6, step: 70, loss: 0.2322, acc: 0.8949
2025-06-15 04:41:04,254 - epoch: 6, step: 80, loss: 0.3047, acc: 0.8548
2025-06-15 04:41:45,766 - epoch: 6, step: 90, loss: 0.1941, acc: 0.9524
2025-06-15 04:42:28,010 - epoch: 6, step: 100, loss: 0.2023, acc: 0.9444
2025-06-15 04:43:18,350 - epoch: 6, step: 110, loss: 0.2813, acc: 0.9364
2025-06-15 04:43:59,202 - epoch: 6, step: 120, loss: 0.3108, acc: 0.8889
2025-06-15 04:44:42,867 - epoch: 6, step: 130, loss: 0.3871, acc: 0.8690
2025-06-15 04:45:27,535 - epoch: 6, step: 140, loss: 0.2484, acc: 0.9280
2025-06-15 04:46:09,247 - epoch: 6, step: 150, loss: 0.1371, acc: 0.9744
2025-06-15 04:46:43,993 - epoch: 6, step: 160, loss: 0.1794, acc: 0.9267
2025-06-15 04:47:29,940 - epoch: 6, step: 170, loss: 0.2493, acc: 0.9167
2025-06-15 04:48:07,965 - epoch: 6, step: 180, loss: 0.2918, acc: 0.8179
2025-06-15 04:48:53,644 - epoch: 6, step: 190, loss: 0.0876, acc: 1.0000
2025-06-15 04:48:59,675 - train_loss:0.25178 train_acc:0.901
2025-06-15 04:50:39,593 - val_loss:0.33314 val_acc:0.886 

2025-06-15 04:50:42,396 - save model,acc:0.886
2025-06-15 04:50:42,397 - -----------Epoch:7-----------
2025-06-15 04:50:45,060 - epoch: 7, step: 0, loss: 0.4433, acc: 0.8750
2025-06-15 04:51:27,343 - epoch: 7, step: 10, loss: 0.3712, acc: 0.8707
2025-06-15 04:52:11,647 - epoch: 7, step: 20, loss: 0.3145, acc: 0.8833
2025-06-15 04:52:54,459 - epoch: 7, step: 30, loss: 0.3840, acc: 0.8524
2025-06-15 04:53:51,866 - epoch: 7, step: 40, loss: 0.1599, acc: 0.9444
2025-06-15 04:54:34,482 - epoch: 7, step: 50, loss: 0.2868, acc: 0.9556
2025-06-15 04:55:17,563 - epoch: 7, step: 60, loss: 0.2420, acc: 0.8268
2025-06-15 04:55:57,079 - epoch: 7, step: 70, loss: 0.2806, acc: 0.9333
2025-06-15 04:56:47,631 - epoch: 7, step: 80, loss: 0.1567, acc: 0.9583
2025-06-15 04:57:30,631 - epoch: 7, step: 90, loss: 0.1636, acc: 0.9667
2025-06-15 04:58:15,485 - epoch: 7, step: 100, loss: 0.1741, acc: 0.9048
2025-06-15 04:58:55,102 - epoch: 7, step: 110, loss: 0.4585, acc: 0.8500
2025-06-15 04:59:42,169 - epoch: 7, step: 120, loss: 0.2473, acc: 0.8767
2025-06-15 05:00:20,322 - epoch: 7, step: 130, loss: 0.3374, acc: 0.8194
2025-06-15 05:00:56,745 - epoch: 7, step: 140, loss: 0.2248, acc: 0.9697
2025-06-15 05:01:41,583 - epoch: 7, step: 150, loss: 0.2360, acc: 0.8903
2025-06-15 05:02:28,969 - epoch: 7, step: 160, loss: 0.3489, acc: 0.8426
2025-06-15 05:03:10,191 - epoch: 7, step: 170, loss: 0.0589, acc: 1.0000
2025-06-15 05:03:45,391 - epoch: 7, step: 180, loss: 0.1768, acc: 0.9375
2025-06-15 05:04:31,469 - epoch: 7, step: 190, loss: 0.3562, acc: 0.8598
2025-06-15 05:04:38,274 - train_loss:0.24149 train_acc:0.909
2025-06-15 05:06:18,049 - val_loss:0.32662 val_acc:0.886 

2025-06-15 05:06:20,833 - save model,acc:0.886
2025-06-15 05:06:20,833 - -----------Epoch:8-----------
2025-06-15 05:06:28,577 - epoch: 8, step: 0, loss: 0.1418, acc: 0.9333
2025-06-15 05:07:14,100 - epoch: 8, step: 10, loss: 0.3086, acc: 0.8611
2025-06-15 05:08:00,108 - epoch: 8, step: 20, loss: 0.1339, acc: 0.9815
2025-06-15 05:08:40,272 - epoch: 8, step: 30, loss: 0.1138, acc: 0.9722
2025-06-15 05:09:21,406 - epoch: 8, step: 40, loss: 0.1649, acc: 0.9111
2025-06-15 05:09:59,419 - epoch: 8, step: 50, loss: 0.1578, acc: 0.9407
2025-06-15 05:10:38,750 - epoch: 8, step: 60, loss: 0.1084, acc: 0.9804
2025-06-15 05:11:22,920 - epoch: 8, step: 70, loss: 0.1968, acc: 0.8838
2025-06-15 05:12:09,056 - epoch: 8, step: 80, loss: 0.1187, acc: 0.9778
2025-06-15 05:12:56,801 - epoch: 8, step: 90, loss: 0.1769, acc: 0.8424
2025-06-15 05:13:41,888 - epoch: 8, step: 100, loss: 0.2561, acc: 0.9375
2025-06-15 05:14:24,560 - epoch: 8, step: 110, loss: 0.3327, acc: 0.9286
2025-06-15 05:15:07,176 - epoch: 8, step: 120, loss: 0.4115, acc: 0.8455
2025-06-15 05:15:46,173 - epoch: 8, step: 130, loss: 0.2628, acc: 0.9333
2025-06-15 05:16:32,142 - epoch: 8, step: 140, loss: 0.1331, acc: 0.8333
2025-06-15 05:17:12,064 - epoch: 8, step: 150, loss: 0.2388, acc: 0.9444
2025-06-15 05:18:00,935 - epoch: 8, step: 160, loss: 0.1903, acc: 0.9167
2025-06-15 05:18:42,244 - epoch: 8, step: 170, loss: 0.1948, acc: 0.8389
2025-06-15 05:19:24,076 - epoch: 8, step: 180, loss: 0.3055, acc: 0.9231
2025-06-15 05:20:03,229 - epoch: 8, step: 190, loss: 0.2282, acc: 0.9078
2025-06-15 05:20:11,020 - train_loss:0.22870 train_acc:0.909
2025-06-15 05:21:50,445 - val_loss:0.31118 val_acc:0.889 

2025-06-15 05:21:53,248 - save model,acc:0.889
2025-06-15 05:21:53,248 - -----------Epoch:9-----------
2025-06-15 05:21:57,415 - epoch: 9, step: 0, loss: 0.3187, acc: 0.9072
2025-06-15 05:22:50,510 - epoch: 9, step: 10, loss: 0.1162, acc: 0.9328
2025-06-15 05:23:38,313 - epoch: 9, step: 20, loss: 0.1116, acc: 0.9762
2025-06-15 05:24:20,676 - epoch: 9, step: 30, loss: 0.1839, acc: 0.9608
2025-06-15 05:25:03,398 - epoch: 9, step: 40, loss: 0.2030, acc: 0.8944
2025-06-15 05:25:39,583 - epoch: 9, step: 50, loss: 0.3273, acc: 0.9139
2025-06-15 05:26:20,961 - epoch: 9, step: 60, loss: 0.3026, acc: 0.8371
2025-06-15 05:27:06,749 - epoch: 9, step: 70, loss: 0.1582, acc: 0.8722
2025-06-15 05:27:45,853 - epoch: 9, step: 80, loss: 0.4316, acc: 0.8810
2025-06-15 05:28:26,402 - epoch: 9, step: 90, loss: 0.1188, acc: 0.9722
2025-06-15 05:29:06,241 - epoch: 9, step: 100, loss: 0.2807, acc: 0.8971
2025-06-15 05:29:47,977 - epoch: 9, step: 110, loss: 0.3902, acc: 0.8419
2025-06-15 05:30:31,827 - epoch: 9, step: 120, loss: 0.1814, acc: 0.9833
2025-06-15 05:31:17,205 - epoch: 9, step: 130, loss: 0.2242, acc: 0.8364
2025-06-15 05:31:56,671 - epoch: 9, step: 140, loss: 0.3572, acc: 0.8952
2025-06-15 05:32:36,415 - epoch: 9, step: 150, loss: 0.1729, acc: 0.9364
2025-06-15 05:33:22,020 - epoch: 9, step: 160, loss: 0.1395, acc: 1.0000
2025-06-15 05:34:07,148 - epoch: 9, step: 170, loss: 0.3063, acc: 0.8908
2025-06-15 05:34:52,503 - epoch: 9, step: 180, loss: 0.0917, acc: 0.9333
2025-06-15 05:35:35,497 - epoch: 9, step: 190, loss: 0.1641, acc: 0.9444
2025-06-15 05:35:44,903 - train_loss:0.22254 train_acc:0.913
2025-06-15 05:37:24,689 - val_loss:0.29353 val_acc:0.895 

2025-06-15 05:37:27,416 - save model,acc:0.895
2025-06-15 05:39:10,060 - --------------------- test results-------------------------------
2025-06-15 05:39:10,060 - acc:0.8829937  prec:[0.9243028 0.8541667 0.9015958]  rec:[0.93172693 0.7935484  0.9237057 ]  f1:[0.928      0.82274246 0.91251683]
2025-06-15 05:39:10,061 - confusion: 
[[232   4  13]
 [  8 123  24]
 [ 11  17 339]]
2025-06-15 05:39:10,123 - the running time is: 9445.4 s
